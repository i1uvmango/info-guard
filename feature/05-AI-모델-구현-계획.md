# AI λ¨λΈ κµ¬ν„ κ³„ν

## π― **AI λ¨λΈ κ°μ”**
Info-Guardμ AI λ¨λΈμ€ YouTube μμƒμ μ‹ λΆ°λ„λ¥Ό λ‹¤κ°λ„λ΅ λ¶„μ„ν•λ” ν•µμ‹¬ μ‹μ¤ν…μ…λ‹λ‹¤. κ°μ • λ¶„μ„, νΈν–¥ κ°μ§€, ν©νΈ μ²΄ν‚Ή, μ½ν…μΈ  λ¶„λ¥ λ“±μ„ ν†µν•΄ μΆ…ν•©μ μΈ μ‹ λΆ°λ„ μ μλ¥Ό μ‚°μ¶ν•©λ‹λ‹¤.

## π—οΈ **AI λ¨λΈ μ•„ν‚¤ν…μ²**

### 1. λ¨λΈ κµ¬μ΅°
```
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚   Input Text   β”‚    β”‚  Preprocessing  β”‚    β”‚   AI Models     β”‚
β”‚   (μλ§‰/μ„¤λ…)   β”‚β”€β”€β”€β–Ίβ”‚   (μ •κ·ν™”/ν† ν°ν™”) β”‚β”€β”€β”€β–Ίβ”‚   (λ¶„μ„ μ—”μ§„)    β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
                                β”‚                       β”‚
                                β–Ό                       β–Ό
                       β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
                       β”‚   Text Utils   β”‚    β”‚  Score Fusion  β”‚
                       β”‚   (μ ν‹Έλ¦¬ν‹°)     β”‚    β”‚   (μ μ ν†µν•©)    β”‚
                       β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”    β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
```

### 2. λ””λ ‰ν† λ¦¬ κµ¬μ΅°
```
src/python-server/app/ai/
β”β”€β”€ __init__.py
β”β”€β”€ base.py              # κΈ°λ³Έ λ¨λΈ ν΄λμ¤
β”β”€β”€ sentiment.py         # κ°μ • λ¶„μ„
β”β”€β”€ bias.py             # νΈν–¥ κ°μ§€
β”β”€β”€ credibility.py      # μ‹ λΆ°λ„ λ¶„μ„
β”β”€β”€ fact_checker.py     # ν©νΈ μ²΄μ»¤
β”β”€β”€ classifier.py       # μ½ν…μΈ  λ¶„λ¥
β””β”€β”€ ensemble.py         # μ•™μƒλΈ” λ¨λΈ
```

## π¤– **ν•µμ‹¬ AI λ¨λΈ**

### 1. κ°μ • λ¶„μ„ λ¨λΈ (Sentiment Analysis)
```python
# κµ¬ν„ μ„μΉ: src/python-server/app/ai/sentiment.py
# κµ¬ν„ ν΄λμ¤: SentimentAnalyzer

class SentimentAnalyzer(BaseModel):
    def __init__(self):
        self.model = self._load_model()
        self.tokenizer = self._load_tokenizer()
    
    def analyze(self, text: str) -> Dict[str, float]:
        """ν…μ¤νΈ κ°μ • λ¶„μ„"""
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
        outputs = self.model(**inputs)
        
        # κ°μ • μ μ κ³„μ‚° (-100 ~ 100)
        sentiment_score = self._calculate_sentiment_score(outputs)
        
        return {
            "sentiment_score": sentiment_score,
            "confidence": self._get_confidence(outputs),
            "emotions": self._extract_emotions(outputs)
        }
    
    def _calculate_sentiment_score(self, outputs) -> float:
        """κ°μ • μ μ κ³„μ‚°"""
        logits = outputs.logits
        probs = torch.softmax(logits, dim=-1)
        
        # κΈμ •/λ¶€μ •/μ¤‘λ¦½ ν™•λ¥ 
        positive_prob = probs[0][1].item()
        negative_prob = probs[0][2].item()
        neutral_prob = probs[0][0].item()
        
        # -100 ~ 100 μ μλ΅ λ³€ν™
        score = (positive_prob - negative_prob) * 100
        return round(score, 2)
```

### 2. νΈν–¥ κ°μ§€ λ¨λΈ (Bias Detection)
```python
# κµ¬ν„ μ„μΉ: src/python-server/app/ai/bias.py
# κµ¬ν„ ν΄λμ¤: BiasDetector

class BiasDetector(BaseModel):
    def __init__(self):
        self.bias_keywords = self._load_bias_keywords()
        self.political_terms = self._load_political_terms()
    
    def detect_bias(self, text: str) -> Dict[str, Any]:
        """νΈν–¥μ„± κ°μ§€"""
        bias_score = 0
        bias_types = []
        
        # ν‚¤μ›λ“ κΈ°λ° νΈν–¥ κ°μ§€
        keyword_bias = self._detect_keyword_bias(text)
        bias_score += keyword_bias['score']
        bias_types.extend(keyword_bias['types'])
        
        # μ •μΉμ  νΈν–¥ κ°μ§€
        political_bias = self._detect_political_bias(text)
        bias_score += political_bias['score']
        bias_types.extend(political_bias['types'])
        
        # μ–Έμ–΄μ  νΈν–¥ κ°μ§€
        linguistic_bias = self._detect_linguistic_bias(text)
        bias_score += linguistic_bias['score']
        bias_types.extend(linguistic_bias['types'])
        
        return {
            "bias_score": max(-100, min(100, bias_score)),  # -100 ~ 100
            "bias_types": list(set(bias_types)),
            "confidence": self._calculate_confidence(bias_score),
            "details": {
                "keyword_bias": keyword_bias,
                "political_bias": political_bias,
                "linguistic_bias": linguistic_bias
            }
        }
    
    def _detect_keyword_bias(self, text: str) -> Dict[str, Any]:
        """ν‚¤μ›λ“ κΈ°λ° νΈν–¥ κ°μ§€"""
        bias_score = 0
        bias_types = []
        
        text_lower = text.lower()
        
        # κ·Ήλ‹¨μ  ν‘ν„ κ°μ§€
        extreme_words = ['μ λ€', 'μ™„λ²½', 'μµκ³ ', 'μµμ•…', 'μ™„μ „ν', 'μ „ν€']
        for word in extreme_words:
            if word in text_lower:
                bias_score += 15
                bias_types.append('extreme_language')
        
        # κ°μ •μ  ν‘ν„ κ°μ§€
        emotional_words = ['μ¶©κ²©', 'ν­λ΅', 'μ¶©κ²©μ ', 'λ†€λΌμ΄', 'λ―Ώμ„ μ μ—†λ”']
        for word in emotional_words:
            if word in text_lower:
                bias_score += 10
                bias_types.append('emotional_language')
        
        return {
            "score": bias_score,
            "types": bias_types
        }
```

### 3. μ‹ λΆ°λ„ λ¶„μ„ λ¨λΈ (Credibility Analyzer)
```python
# κµ¬ν„ μ„μΉ: src/python-server/app/ai/credibility.py
# κµ¬ν„ ν΄λμ¤: CredibilityAnalyzer

class CredibilityAnalyzer(BaseModel):
    def __init__(self):
        self.fact_checker = FactChecker()
        self.bias_detector = BiasDetector()
        self.sentiment_analyzer = SentimentAnalyzer()
    
    def analyze_credibility(self, text: str, metadata: Dict = None) -> Dict[str, Any]:
        """μΆ…ν•© μ‹ λΆ°λ„ λ¶„μ„"""
        results = {}
        
        # ν©νΈ μ²΄ν‚Ή
        fact_check_result = self.fact_checker.check_facts(text)
        results['fact_check'] = fact_check_result
        
        # νΈν–¥μ„± λ¶„μ„
        bias_result = self.bias_detector.detect_bias(text)
        results['bias'] = bias_result
        
        # κ°μ • λ¶„μ„
        sentiment_result = self.sentiment_analyzer.analyze(text)
        results['sentiment'] = sentiment_result
        
        # μΆ…ν•© μ‹ λΆ°λ„ μ μ κ³„μ‚°
        overall_score = self._calculate_overall_score(results)
        
        return {
            "overall_credibility": overall_score,
            "fact_check_score": fact_check_result['score'],
            "bias_score": bias_result['bias_score'],
            "sentiment_score": sentiment_result['sentiment_score'],
            "detailed_analysis": results,
            "confidence": self._calculate_confidence(results)
        }
    
    def _calculate_overall_score(self, results: Dict) -> float:
        """μΆ…ν•© μ‹ λΆ°λ„ μ μ κ³„μ‚°"""
        fact_score = results['fact_check']['score'] * 0.4      # 40% κ°€μ¤‘μΉ
        bias_score = (100 - abs(results['bias']['bias_score'])) * 0.3  # 30% κ°€μ¤‘μΉ
        sentiment_score = (100 - abs(results['sentiment']['sentiment_score'])) * 0.2  # 20% κ°€μ¤‘μΉ
        metadata_score = self._calculate_metadata_score(results.get('metadata', {})) * 0.1  # 10% κ°€μ¤‘μΉ
        
        total_score = fact_score + bias_score + sentiment_score + metadata_score
        return max(0, min(100, round(total_score, 2)))
```

### 4. ν©νΈ μ²΄μ»¤ (Fact Checker)
```python
# κµ¬ν„ μ„μΉ: src/python-server/app/ai/fact_checker.py
# κµ¬ν„ ν΄λμ¤: FactChecker

class FactChecker(BaseModel):
    def __init__(self):
        self.verification_sources = self._load_verification_sources()
        self.fact_patterns = self._load_fact_patterns()
    
    def check_facts(self, text: str) -> Dict[str, Any]:
        """μ‚¬μ‹¤ μ—¬λ¶€ κ²€μ¦"""
        facts = self._extract_facts(text)
        verified_facts = []
        unverified_facts = []
        
        for fact in facts:
            verification_result = self._verify_fact(fact)
            if verification_result['verified']:
                verified_facts.append(verification_result)
            else:
                unverified_facts.append(verification_result)
        
        # ν©νΈ μ²΄ν¬ μ μ κ³„μ‚°
        fact_check_score = self._calculate_fact_check_score(verified_facts, unverified_facts)
        
        return {
            "score": fact_check_score,
            "verified_facts": verified_facts,
            "unverified_facts": unverified_facts,
            "total_facts": len(facts),
            "verification_rate": len(verified_facts) / len(facts) if facts else 0
        }
    
    def _extract_facts(self, text: str) -> List[str]:
        """ν…μ¤νΈμ—μ„ μ‚¬μ‹¤ μ¶”μ¶"""
        facts = []
        
        # μ«μ κΈ°λ° μ‚¬μ‹¤ ν¨ν„΄
        number_patterns = [
            r'(\d+)\s*(λ…|κ°|κ±΄|%|μ›|λ‹¬λ¬|μ‹κ°„|λ¶„|μ΄)',
            r'(\d{4})λ…„\s*(\d{1,2})μ›”',
            r'(\d+)μ›”\s*(\d+)μΌ'
        ]
        
        for pattern in number_patterns:
            matches = re.findall(pattern, text)
            facts.extend([f"μ«μ μ •λ³΄: {match}" for match in matches])
        
        # λ‚ μ§ κΈ°λ° μ‚¬μ‹¤ ν¨ν„΄
        date_patterns = [
            r'(\d{4})λ…„\s*(\d{1,2})μ›”\s*(\d{1,2})μΌ',
            r'(\d{1,2})μ›”\s*(\d{1,2})μΌ'
        ]
        
        for pattern in date_patterns:
            matches = re.findall(pattern, text)
            facts.extend([f"λ‚ μ§ μ •λ³΄: {match}" for match in matches])
        
        return facts
```

## π”§ **λ¨λΈ μµμ ν™” λ° μ„±λ¥**

### 1. λ°°μΉ μ²λ¦¬
```python
# κµ¬ν„ μ„μΉ: src/python-server/app/services/batch_processor.py
# κµ¬ν„ ν΄λμ¤: BatchProcessor

class BatchProcessor:
    def __init__(self, batch_size: int = 32):
        self.batch_size = batch_size
        self.models = self._initialize_models()
    
    async def process_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """λ°°μΉ λ‹¨μ„λ΅ ν…μ¤νΈ μ²λ¦¬"""
        results = []
        
        for i in range(0, len(texts), self.batch_size):
            batch = texts[i:i + self.batch_size]
            batch_results = await self._process_single_batch(batch)
            results.extend(batch_results)
        
        return results
    
    async def _process_single_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """λ‹¨μΌ λ°°μΉ μ²λ¦¬"""
        tasks = []
        
        for text in texts:
            task = self._analyze_single_text(text)
            tasks.append(task)
        
        batch_results = await asyncio.gather(*tasks)
        return batch_results
    
    async def _analyze_single_text(self, text: str) -> Dict[str, Any]:
        """λ‹¨μΌ ν…μ¤νΈ λ¶„μ„"""
        start_time = time.time()
        
        # λ³‘λ ¬λ΅ μ—¬λ¬ λ¨λΈ μ‹¤ν–‰
        sentiment_task = self.models['sentiment'].analyze(text)
        bias_task = self.models['bias'].detect_bias(text)
        credibility_task = self.models['credibility'].analyze_credibility(text)
        
        results = await asyncio.gather(sentiment_task, bias_task, credibility_task)
        
        processing_time = (time.time() - start_time) * 1000  # ms
        
        return {
            "text": text,
            "sentiment": results[0],
            "bias": results[1],
            "credibility": results[2],
            "processing_time": processing_time
        }
```

### 2. λ¨λΈ μΊμ‹±
```python
# κµ¬ν„ μ„μΉ: src/python-server/app/services/cache.py
# κµ¬ν„ ν΄λμ¤: AnalysisCache

class AnalysisCache:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.cache_ttl = 3600  # 1μ‹κ°„
    
    async def get_cached_analysis(self, text_hash: str) -> Optional[Dict]:
        """μΊμ‹λ λ¶„μ„ κ²°κ³Ό μ΅°ν"""
        cache_key = f"analysis:{text_hash}"
        cached_data = await self.redis.get(cache_key)
        
        if cached_data:
            return json.loads(cached_data)
        return None
    
    async def cache_analysis_result(self, text_hash: str, result: Dict):
        """λ¶„μ„ κ²°κ³Ό μΊμ‹±"""
        cache_key = f"analysis:{text_hash}"
        await self.redis.setex(
            cache_key,
            self.cache_ttl,
            json.dumps(result, ensure_ascii=False)
        )
    
    def _generate_text_hash(self, text: str) -> str:
        """ν…μ¤νΈ ν•΄μ‹ μƒμ„±"""
        return hashlib.md5(text.encode('utf-8')).hexdigest()
```

## π― **κµ¬ν„ μ™„λ£ μ²΄ν¬λ¦¬μ¤νΈ**

- [ ] κΈ°λ³Έ λ¨λΈ ν΄λμ¤ κµ¬μ΅°
- [ ] κ°μ • λ¶„μ„ λ¨λΈ
- [ ] νΈν–¥ κ°μ§€ λ¨λΈ
- [ ] μ‹ λΆ°λ„ λ¶„μ„ λ¨λΈ
- [ ] ν©νΈ μ²΄μ»¤ κΈ°λ³Έ κµ¬μ΅°
- [ ] λ°°μΉ μ²λ¦¬ μ‹μ¤ν…
- [ ] λ¨λΈ μΊμ‹± μ‹μ¤ν…

- [ ] ν©νΈ μ²΄μ»¤ μ™„μ„±
- [ ] μ½ν…μΈ  λ¶„λ¥ λ¨λΈ
- [ ] λ¨λΈ μ„±λ¥ μµμ ν™”

- [ ] λ¨λΈ μ •ν™•λ„ ν‰κ°€
- [ ] μλ™ λ¨λΈ μ—…λ°μ΄νΈ
- [ ] A/B ν…μ¤νΈ μ‹μ¤ν…
- [ ] λ¨λΈ λ²„μ „ κ΄€λ¦¬
