# Python ì„œë²„ êµ¬í˜„ ê³„íš

## ğŸ¯ **Python ì„œë²„ ê°œìš”**
Info-Guard Python ì„œë²„ëŠ” AI ëª¨ë¸ì„ í†µí•œ YouTube ì˜ìƒ ì‹ ë¢°ë„ ë¶„ì„ì˜ í•µì‹¬ ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. FastAPI ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ì‹¤ì‹œê°„ ë¶„ì„ê³¼ WebSocket í†µì‹ ì„ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸ—ï¸ **ì•„í‚¤í…ì²˜ êµ¬ì¡°**

### 1. ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
src/python-server/
â”œâ”€â”€ main.py                    # ë©”ì¸ ì„œë²„ ì§„ì…ì 
â”œâ”€â”€ app/                       # ì• í”Œë¦¬ì¼€ì´ì…˜ í•µì‹¬
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                  # í•µì‹¬ ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py          # ì„¤ì • ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ logging.py         # ë¡œê¹… ì‹œìŠ¤í…œ
â”‚   â”‚   â””â”€â”€ exceptions.py      # ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ api/                   # API ë ˆì´ì–´
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ deps.py            # ì˜ì¡´ì„± ì£¼ì…
â”‚   â”‚   â”œâ”€â”€ middleware.py      # ë¯¸ë“¤ì›¨ì–´
â”‚   â”‚   â””â”€â”€ v1/                # API ë²„ì „ 1
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ health.py      # í—¬ìŠ¤ì²´í¬
â”‚   â”‚       â”œâ”€â”€ analysis.py    # ë¶„ì„ API
â”‚   â”‚       â””â”€â”€ websocket.py   # WebSocket
â”‚   â”œâ”€â”€ models/                # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ analysis.py        # ë¶„ì„ ê´€ë ¨ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ youtube.py         # YouTube ê´€ë ¨ ëª¨ë¸
â”‚   â”‚   â””â”€â”€ common.py          # ê³µí†µ ëª¨ë¸
â”‚   â”œâ”€â”€ services/              # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ analysis.py        # ë¶„ì„ ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ youtube.py         # YouTube ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ ai_models.py       # AI ëª¨ë¸ ì„œë¹„ìŠ¤
â”‚   â”‚   â””â”€â”€ cache.py           # ìºì‹œ ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ ai/                    # AI ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py            # ê¸°ë³¸ ëª¨ë¸ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ sentiment.py       # ê°ì • ë¶„ì„
â”‚   â”‚   â”œâ”€â”€ bias.py            # í¸í–¥ ê°ì§€
â”‚   â”‚   â”œâ”€â”€ credibility.py     # ì‹ ë¢°ë„ ë¶„ì„
â”‚   â”‚   â””â”€â”€ classifier.py      # ì½˜í…ì¸  ë¶„ë¥˜
â”‚   â””â”€â”€ utils/                 # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ text.py            # í…ìŠ¤íŠ¸ ì²˜ë¦¬
â”‚       â””â”€â”€ validators.py      # ê²€ì¦ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ tests/                     # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”œâ”€â”€ requirements.txt            # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
â””â”€â”€ Dockerfile                 # Docker ì„¤ì •
```

## ğŸš€ **êµ¬í˜„ ë‹¨ê³„ë³„ ê³„íš**

### **1ë‹¨ê³„: ê¸°ë³¸ êµ¬ì¡° ë° ì„¤ì •**

#### 1.1 ë©”ì¸ ì„œë²„ íŒŒì¼ (`main.py`)
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/main.py
# êµ¬í˜„ í•¨ìˆ˜: create_app(), start_server()

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.core.config import settings
from app.api.v1 import health, analysis, websocket

def create_app():
    app = FastAPI(
        title="Info-Guard AI Analysis Server",
        description="YouTube ì˜ìƒ ì‹ ë¢°ë„ ë¶„ì„ AI ì„œë²„",
        version="1.0.0"
    )
    
    # CORS ì„¤ì •
    app.add_middleware(
        CORSMiddleware,
        allow_origins=settings.ALLOWED_ORIGINS,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # API ë¼ìš°í„° ë“±ë¡
    app.include_router(health.router, prefix="/api/v1", tags=["health"])
    app.include_router(analysis.router, prefix="/api/v1", tags=["analysis"])
    app.include_router(websocket.router, prefix="/api/v1", tags=["websocket"])
    
    return app

app = create_app()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### 1.2 ì„¤ì • ê´€ë¦¬ (`app/core/config.py`)
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/core/config.py
# êµ¬í˜„ í´ë˜ìŠ¤: Settings

from pydantic_settings import BaseSettings
from typing import List

class Settings(BaseSettings):
    # ì„œë²„ ì„¤ì •
    HOST: str = "0.0.0.0"
    PORT: int = 8000
    DEBUG: bool = False
    
    # CORS ì„¤ì •
    ALLOWED_ORIGINS: List[str] = ["http://localhost:3000", "chrome-extension://*"]
    
    # YouTube API ì„¤ì •
    YOUTUBE_API_KEY: str
    
    # AI ëª¨ë¸ ì„¤ì •
    MODEL_PATH: str = "./models"
    GPU_ENABLED: bool = True
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    DATABASE_URL: str = "postgresql://user:password@localhost/info_guard"
    REDIS_URL: str = "redis://localhost:6379"
    
    class Config:
        env_file = ".env"

settings = Settings()
```

### **2ë‹¨ê³„: AI ëª¨ë¸ êµ¬í˜„**

#### 2.1 ê¸°ë³¸ AI ëª¨ë¸ í´ë˜ìŠ¤ (`app/ai/base.py`)
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/ai/base.py
# êµ¬í˜„ í´ë˜ìŠ¤: BaseAIModel

from abc import ABC, abstractmethod
from typing import Any, Dict, Optional
import torch
import numpy as np

class BaseAIModel(ABC):
    def __init__(self, model_path: str, device: str = "auto"):
        self.model_path = model_path
        self.device = self._get_device(device)
        self.model = None
        self.tokenizer = None
        self._load_model()
    
    def _get_device(self, device: str) -> str:
        if device == "auto":
            return "cuda" if torch.cuda.is_available() else "cpu"
        return device
    
    @abstractmethod
    def _load_model(self):
        """ëª¨ë¸ ë¡œë“œ êµ¬í˜„"""
        pass
    
    @abstractmethod
    def predict(self, text: str) -> Dict[str, Any]:
        """ì˜ˆì¸¡ ìˆ˜í–‰ êµ¬í˜„"""
        pass
    
    def preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        return text.strip().lower()
    
    def postprocess_output(self, output: Any) -> Dict[str, Any]:
        """ì¶œë ¥ í›„ì²˜ë¦¬"""
        return {"result": output}
```

#### 2.2 ê°ì • ë¶„ì„ ëª¨ë¸ (`app/ai/sentiment.py`)
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/ai/sentiment.py
# êµ¬í˜„ í´ë˜ìŠ¤: SentimentAnalyzer

from .base import BaseAIModel
from transformers import pipeline
from typing import Dict, Any

class SentimentAnalyzer(BaseAIModel):
    def _load_model(self):
        """ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ"""
        self.analyzer = pipeline(
            "sentiment-analysis",
            model="nlptown/bert-base-multilingual-uncased-sentiment",
            device=0 if self.device == "cuda" else -1
        )
    
    def predict(self, text: str) -> Dict[str, Any]:
        """ê°ì • ë¶„ì„ ìˆ˜í–‰"""
        processed_text = self.preprocess_text(text)
        result = self.analyzer(processed_text)
        
        # ê°ì • ì ìˆ˜ ê³„ì‚° (1-5 ìŠ¤ì¼€ì¼ì„ 0-100ìœ¼ë¡œ ë³€í™˜)
        score = float(result[0]['label'].split()[0]) * 20
        
        return {
            "sentiment_score": score,
            "sentiment_label": result[0]['label'],
            "confidence": result[0]['score'],
            "text": text
        }
```

#### 2.3 í¸í–¥ ê°ì§€ ëª¨ë¸ (`app/ai/bias.py`)
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/ai/bias.py
# êµ¬í˜„ í´ë˜ìŠ¤: BiasDetector

from .base import BaseAIModel
from transformers import pipeline
from typing import Dict, Any, List

class BiasDetector(BaseAIModel):
    def _load_model(self):
        """í¸í–¥ ê°ì§€ ëª¨ë¸ ë¡œë“œ"""
        self.classifier = pipeline(
            "text-classification",
            model="facebook/bart-large-mnli",
            device=0 if self.device == "cuda" else -1
        )
    
    def predict(self, text: str) -> Dict[str, Any]:
        """í¸í–¥ì„± ë¶„ì„ ìˆ˜í–‰"""
        processed_text = self.preprocess_text(text)
        
        # í¸í–¥ ìœ í˜•ë³„ ë¶„ë¥˜
        bias_types = [
            "political bias",
            "gender bias", 
            "racial bias",
            "religious bias",
            "economic bias"
        ]
        
        bias_scores = {}
        for bias_type in bias_types:
            result = self.classifier(processed_text, candidate_labels=[bias_type, "neutral"])
            bias_scores[bias_type] = result['scores'][0]
        
        # ì „ì²´ í¸í–¥ ì ìˆ˜ ê³„ì‚°
        total_bias_score = sum(bias_scores.values()) / len(bias_scores) * 100
        
        return {
            "bias_score": total_bias_score,
            "bias_breakdown": bias_scores,
            "text": text
        }
```

### **3ë‹¨ê³„: API êµ¬í˜„**

#### 3.1 ë¶„ì„ API (`app/api/v1/analysis.py`)
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/api/v1/analysis.py
# êµ¬í˜„ í•¨ìˆ˜: analyze_video(), get_analysis_result()

from fastapi import APIRouter, HTTPException, Depends
from app.models.analysis import AnalysisRequest, AnalysisResponse
from app.services.analysis import AnalysisService
from app.api.deps import get_analysis_service

router = APIRouter()

@router.post("/analyze", response_model=AnalysisResponse)
async def analyze_video(
    request: AnalysisRequest,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """ë¹„ë””ì˜¤ ë¶„ì„ ìš”ì²­"""
    try:
        result = await analysis_service.analyze_video(
            video_id=request.video_id,
            video_url=request.video_url,
            transcript=request.transcript
        )
        return AnalysisResponse(
            success=True,
            data=result,
            message="ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/result/{video_id}", response_model=AnalysisResponse)
async def get_analysis_result(
    video_id: str,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    try:
        result = await analysis_service.get_analysis_result(video_id)
        if not result:
            raise HTTPException(status_code=404, detail="ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return AnalysisResponse(
            success=True,
            data=result,
            message="ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤."
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 3.2 WebSocket API (`app/api/v1/websocket.py`)
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/api/v1/websocket.py
# êµ¬í˜„ í•¨ìˆ˜: websocket_endpoint()

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from app.services.analysis import AnalysisService
from app.api.deps import get_analysis_service
import json

router = APIRouter()

@router.websocket("/ws/analysis/{video_id}")
async def websocket_endpoint(
    websocket: WebSocket,
    video_id: str,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """ì‹¤ì‹œê°„ ë¶„ì„ WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()
    
    try:
        # ë¶„ì„ ì‹œì‘ ì•Œë¦¼
        await websocket.send_text(json.dumps({
            "type": "analysis_started",
            "video_id": video_id,
            "message": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤."
        }))
        
        # ì‹¤ì‹œê°„ ë¶„ì„ ìˆ˜í–‰
        async for progress in analysis_service.analyze_video_realtime(video_id):
            await websocket.send_text(json.dumps({
                "type": "analysis_progress",
                "video_id": video_id,
                "progress": progress
            }))
        
        # ë¶„ì„ ì™„ë£Œ ì•Œë¦¼
        final_result = await analysis_service.get_analysis_result(video_id)
        await websocket.send_text(json.dumps({
            "type": "analysis_completed",
            "video_id": video_id,
            "result": final_result
        }))
        
    except WebSocketDisconnect:
        print(f"Client {video_id} disconnected")
    except Exception as e:
        await websocket.send_text(json.dumps({
            "type": "error",
            "message": str(e)
        }))
```

### **4ë‹¨ê³„: ì„œë¹„ìŠ¤ ë ˆì´ì–´ êµ¬í˜„**

#### 4.1 ë¶„ì„ ì„œë¹„ìŠ¤ (`app/services/analysis.py`)
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/services/analysis.py
# êµ¬í˜„ í´ë˜ìŠ¤: AnalysisService

from app.services.ai_models import AIModelService
from app.services.youtube import YouTubeService
from app.services.cache import CacheService
from app.models.analysis import AnalysisResult
from typing import AsyncGenerator, Dict, Any
import asyncio

class AnalysisService:
    def __init__(
        self,
        ai_service: AIModelService,
        youtube_service: YouTubeService,
        cache_service: CacheService
    ):
        self.ai_service = ai_service
        self.youtube_service = youtube_service
        self.cache_service = cache_service
    
    async def analyze_video(
        self,
        video_id: str,
        video_url: str = None,
        transcript: str = None
    ) -> AnalysisResult:
        """ë¹„ë””ì˜¤ ë¶„ì„ ìˆ˜í–‰"""
        # ìºì‹œ í™•ì¸
        cached_result = await self.cache_service.get_analysis(video_id)
        if cached_result:
            return cached_result
        
        # YouTube ë°ì´í„° ìˆ˜ì§‘
        if not transcript:
            video_data = await self.youtube_service.get_video_data(video_id)
            transcript = video_data.get('transcript', '')
        
        # AI ë¶„ì„ ìˆ˜í–‰
        sentiment_result = await self.ai_service.analyze_sentiment(transcript)
        bias_result = await self.ai_service.analyze_bias(transcript)
        credibility_result = await self.ai_service.analyze_credibility(transcript)
        
        # ì¢…í•© ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        overall_score = self._calculate_overall_score(
            sentiment_result, bias_result, credibility_result
        )
        
        # ê²°ê³¼ ìƒì„±
        result = AnalysisResult(
            video_id=video_id,
            video_url=video_url,
            credibility_score=overall_score,
            sentiment_score=sentiment_result['sentiment_score'],
            bias_score=bias_result['bias_score'],
            analysis_breakdown={
                'sentiment': sentiment_result,
                'bias': bias_result,
                'credibility': credibility_result
            }
        )
        
        # ìºì‹œ ì €ì¥
        await self.cache_service.save_analysis(video_id, result)
        
        return result
    
    async def analyze_video_realtime(
        self, video_id: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """ì‹¤ì‹œê°„ ë¶„ì„ ì§„í–‰ìƒí™©"""
        yield {"step": "started", "progress": 0}
        
        # YouTube ë°ì´í„° ìˆ˜ì§‘
        yield {"step": "collecting_data", "progress": 20}
        video_data = await self.youtube_service.get_video_data(video_id)
        
        # ê°ì • ë¶„ì„
        yield {"step": "sentiment_analysis", "progress": 40}
        sentiment_result = await self.ai_service.analyze_sentiment(
            video_data.get('transcript', '')
        )
        
        # í¸í–¥ ê°ì§€
        yield {"step": "bias_detection", "progress": 60}
        bias_result = await self.ai_service.analyze_bias(
            video_data.get('transcript', '')
        )
        
        # ì‹ ë¢°ë„ ë¶„ì„
        yield {"step": "credibility_analysis", "progress": 80}
        credibility_result = await self.ai_service.analyze_credibility(
            video_data.get('transcript', '')
        )
        
        yield {"step": "completed", "progress": 100}
    
    def _calculate_overall_score(
        self,
        sentiment_result: Dict[str, Any],
        bias_result: Dict[str, Any],
        credibility_result: Dict[str, Any]
    ) -> float:
        """ì¢…í•© ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        weights = {
            'sentiment': 0.2,
            'bias': 0.4,
            'credibility': 0.4
        }
        
        # ì ìˆ˜ ê³„ì‚°
        sentiment_score = sentiment_result.get('sentiment_score', 50)
        bias_score = 100 - bias_result.get('bias_score', 50)  # í¸í–¥ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        credibility_score = credibility_result.get('credibility_score', 50)
        
        overall_score = (
            sentiment_score * weights['sentiment'] +
            bias_score * weights['bias'] +
            credibility_score * weights['credibility']
        )
        
        return round(overall_score, 2)
```

## ğŸ§ª **í…ŒìŠ¤íŠ¸ êµ¬í˜„ ê³„íš**

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/tests/test_ai/test_sentiment.py
# êµ¬í˜„ í•¨ìˆ˜: test_sentiment_analyzer()

import pytest
from app.ai.sentiment import SentimentAnalyzer

@pytest.mark.asyncio
async def test_sentiment_analyzer():
    """ê°ì • ë¶„ì„ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    analyzer = SentimentAnalyzer("./models")
    
    # ê¸ì •ì  í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
    positive_result = await analyzer.predict("ì´ ì˜ìƒì€ ì •ë§ ì¢‹ìŠµë‹ˆë‹¤!")
    assert positive_result['sentiment_score'] > 60
    
    # ë¶€ì •ì  í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
    negative_result = await analyzer.predict("ì´ ì˜ìƒì€ ë³„ë¡œì…ë‹ˆë‹¤.")
    assert negative_result['sentiment_score'] < 40
```

### 2. í†µí•© í…ŒìŠ¤íŠ¸
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/tests/test_services/test_analysis_service.py
# êµ¬í˜„ í•¨ìˆ˜: test_analysis_service()

import pytest
from app.services.analysis import AnalysisService
from app.services.ai_models import AIModelService
from app.services.youtube import YouTubeService
from app.services.cache import CacheService

@pytest.mark.asyncio
async def test_analysis_service():
    """ë¶„ì„ ì„œë¹„ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸"""
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    ai_service = AIModelService()
    youtube_service = YouTubeService()
    cache_service = CacheService()
    
    analysis_service = AnalysisService(ai_service, youtube_service, cache_service)
    
    # ë¶„ì„ ìˆ˜í–‰
    result = await analysis_service.analyze_video(
        video_id="test123",
        transcript="ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤."
    )
    
    assert result.video_id == "test123"
    assert 0 <= result.credibility_score <= 100
    assert result.analysis_breakdown is not None
```

## ğŸš€ **ì„±ëŠ¥ ìµœì í™” ê³„íš**

### 1. GPU ê°€ì†
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/core/gpu_config.py
# êµ¬í˜„ í•¨ìˆ˜: setup_gpu(), optimize_model()

import torch
from typing import Optional

def setup_gpu() -> Optional[str]:
    """GPU ì„¤ì • ë° ìµœì í™”"""
    if torch.cuda.is_available():
        device = "cuda"
        # GPU ë©”ëª¨ë¦¬ ìµœì í™”
        torch.cuda.empty_cache()
        torch.backends.cudnn.benchmark = True
        return device
    return "cpu"

def optimize_model(model, device: str):
    """ëª¨ë¸ ìµœì í™”"""
    if device == "cuda":
        model = model.cuda()
        model = torch.nn.DataParallel(model)
    return model
```

### 2. ë°°ì¹˜ ì²˜ë¦¬
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/services/batch_processor.py
# êµ¬í˜„ í´ë˜ìŠ¤: BatchProcessor

class BatchProcessor:
    def __init__(self, batch_size: int = 32):
        self.batch_size = batch_size
    
    async def process_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        results = []
        
        for i in range(0, len(texts), self.batch_size):
            batch = texts[i:i + self.batch_size]
            batch_results = await self._process_single_batch(batch)
            results.extend(batch_results)
        
        return results
```

## ğŸ“Š **ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…**

### 1. ë¡œê¹… ì‹œìŠ¤í…œ
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/core/logging.py
# êµ¬í˜„ í•¨ìˆ˜: setup_logging()

import logging
from app.core.config import settings

def setup_logging():
    """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO if not settings.DEBUG else logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('app.log'),
            logging.StreamHandler()
        ]
    )
```

### 2. ì„±ëŠ¥ ë©”íŠ¸ë¦­
```python
# êµ¬í˜„ ìœ„ì¹˜: src/python-server/app/core/metrics.py
# êµ¬í˜„ í•¨ìˆ˜: track_performance()

import time
from functools import wraps

def track_performance(func):
    """ì„±ëŠ¥ ì¶”ì  ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        result = await func(*args, **kwargs)
        end_time = time.time()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
        processing_time = (end_time - start_time) * 1000  # ms
        print(f"{func.__name__} ì‹¤í–‰ ì‹œê°„: {processing_time:.2f}ms")
        
        return result
    return wrapper
```

## ğŸ¯ **êµ¬í˜„ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸**

- [ ] ê¸°ë³¸ ì„œë²„ êµ¬ì¡° ë° ì„¤ì •
- [ ] AI ëª¨ë¸ í´ë˜ìŠ¤ êµ¬í˜„
- [ ] ê°ì • ë¶„ì„ ëª¨ë¸
- [ ] í¸í–¥ ê°ì§€ ëª¨ë¸
- [ ] ì‹ ë¢°ë„ ë¶„ì„ ëª¨ë¸
- [ ] ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸
- [ ] WebSocket ì‹¤ì‹œê°„ í†µì‹ 
- [ ] ë¶„ì„ ì„œë¹„ìŠ¤ ë¡œì§
- [ ] YouTube API ì—°ë™

- [ ] íŒ©íŠ¸ ì²´ì»¤ ëª¨ë¸ í…ŒìŠ¤íŠ¸
- [ ] ì½˜í…ì¸  ë¶„ë¥˜ ëª¨ë¸ í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ìµœì í™”
- [ ] ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
- [ ] ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
