"""
ì‹ ë¢°ë„ ë¶„ì„ AI ëª¨ë¸
ì‹¤ì œ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ì‹ ë¢°ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import asyncio
from typing import Dict, Any, List
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from sentence_transformers import SentenceTransformer
from loguru import logger

from .base import BaseAIModel
from ..models.analysis import CredibilityScore


class CredibilityAnalyzer(BaseAIModel):
    """ì‹ ë¢°ë„ ë¶„ì„ AI ëª¨ë¸"""
    
    def __init__(self):
        super().__init__("credibility_analyzer", "facebook/bart-large-mnli")
        self.sentence_transformer = None
        self.credibility_pipeline = None
        self.claim_detection_pipeline = None
        
    async def load_model(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info(f"ğŸ”„ ì‹ ë¢°ë„ ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_name}")
            
            # BaseAIModelì˜ ê³µí†µ ë¡œë”© ë©”ì„œë“œ ì‚¬ìš©
            success = await self.load_huggingface_model(self.model_path, "text-classification")
            if not success:
                return False
            
            # ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
            self.sentence_transformer = SentenceTransformer(
                'all-MiniLM-L6-v2',
                device=self.device
            )
            
            # ì‚¬ì‹¤ í™•ì¸ íŒŒì´í”„ë¼ì¸
            self.fact_check_pipeline = pipeline(
                "text-classification",
                model="facebook/bart-large-mnli",
                device=0 if self.device.startswith("cuda") else -1,
                batch_size=self.gpu_config.batch_size
            )
            
            # ì£¼ì¥ ê°ì§€ íŒŒì´í”„ë¼ì¸
            self.claim_detection_pipeline = pipeline(
                "text-classification",
                model="microsoft/DialoGPT-medium",
                device=0 if self.device.startswith("cuda") else -1,
                batch_size=self.gpu_config.batch_size
            )
            
            logger.info("âœ… ì‹ ë¢°ë„ ë¶„ì„ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì‹ ë¢°ë„ ë¶„ì„ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    async def analyze(self, text: str, **kwargs) -> CredibilityAnalysis:
        """í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ë¶„ì„"""
        # ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if not await self.ensure_model_loaded():
            logger.warning("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ê°’ ë°˜í™˜")
            return CredibilityAnalysis(
                credibility_score=0.5,
                fact_check_score=0.5,
                source_reliability_score=0.5,
                consistency_score=0.5,
                objectivity_score=0.5,
                credibility_level="ì¤‘ê°„",
                reasoning="ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨"
            )
        
        try:
            logger.info(f"ğŸ” ì‹ ë¢°ë„ ë¶„ì„ ì‹œì‘: {text[:100]}...")
            
            # 1. ì‚¬ì‹¤ í™•ì¸ (Fact-checking)
            fact_check_result = await self._check_facts(text)
            
            # 2. ì¶œì²˜ ì‹ ë¢°ë„ í‰ê°€
            source_credibility = await self._evaluate_source_credibility(text)
            
            # 3. ì£¼ì¥ ê°•ë„ ë¶„ì„
            claim_strength = await self._analyze_claim_strength(text)
            
            # 4. ì¼ê´€ì„± ê²€ì‚¬
            consistency_score = await self._check_consistency(text)
            
            # 5. ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            final_score = self._calculate_final_score(
                fact_check_result,
                source_credibility,
                claim_strength,
                consistency_score
            )
            
            # 6. ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •
            credibility_level = self._determine_credibility_level(final_score)
            
            result = CredibilityAnalysis(
                credibility_score=final_score,
                fact_check_score=fact_check_result,
                source_reliability_score=source_credibility,
                consistency_score=consistency_score,
                objectivity_score=1.0 - claim_strength,  # í¸í–¥ì„±ì´ ë‚®ì„ìˆ˜ë¡ ê°ê´€ì„± ë†’ìŒ
                credibility_level=credibility_level,
                reasoning=f"AI ëª¨ë¸ ê¸°ë°˜ ë‹¤ì¤‘ ìš”ì†Œ ë¶„ì„: ì‚¬ì‹¤í™•ì¸({fact_check_result:.2f}), ì¶œì²˜({source_credibility:.2f}), ì£¼ì¥ê°•ë„({claim_strength:.2f}), ì¼ê´€ì„±({consistency_score:.2f})"
            )
            
            logger.info(f"âœ… ì‹ ë¢°ë„ ë¶„ì„ ì™„ë£Œ: ì ìˆ˜ {final_score:.2f}, ë ˆë²¨ {credibility_level}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì‹ ë¢°ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return CredibilityAnalysis(
                credibility_score=0.5,
                fact_check_score=0.5,
                source_reliability_score=0.5,
                consistency_score=0.5,
                objectivity_score=0.5,
                credibility_level="ì¤‘ê°„",
                reasoning=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )
    
    async def _check_facts(self, text: str) -> float:
        """ì‚¬ì‹¤ í™•ì¸"""
        try:
            # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
            sentences = text.split('.')
            sentences = [s.strip() for s in sentences if s.strip()]
            
            if not sentences:
                return 0.5
            
            # ê° ë¬¸ì¥ì˜ ì‚¬ì‹¤ì„± í‰ê°€
            fact_scores = []
            for sentence in sentences[:5]:  # ìµœëŒ€ 5ê°œ ë¬¸ì¥ë§Œ ë¶„ì„
                if len(sentence) > 10:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸
                    result = self.fact_check_pipeline(sentence)
                    # ê²°ê³¼ë¥¼ 0-1 ì ìˆ˜ë¡œ ë³€í™˜
                    score = self._normalize_fact_check_result(result)
                    fact_scores.append(score)
            
            if fact_scores:
                return sum(fact_scores) / len(fact_scores)
            return 0.5
            
        except Exception as e:
            logger.warning(f"ì‚¬ì‹¤ í™•ì¸ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _evaluate_source_credibility(self, text: str) -> float:
        """ì¶œì²˜ ì‹ ë¢°ë„ í‰ê°€"""
        try:
            # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œ íŒ¨í„´
            credible_patterns = [
                "ì—°êµ¬ì— ë”°ë¥´ë©´", "ì¡°ì‚¬ ê²°ê³¼", "ê³µì‹ ë°œí‘œ", "ì „ë¬¸ê°€ ì˜ê²¬",
                "í•™ìˆ  ë…¼ë¬¸", "peer-reviewed", "ë©”íƒ€ ë¶„ì„", "ì‹œìŠ¤í…œ ë¦¬ë·°"
            ]
            
            # ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” í‚¤ì›Œë“œ íŒ¨í„´
            non_credible_patterns = [
                "ì†Œë¬¸ì— ë”°ë¥´ë©´", "ìµëª…ì˜ ì†Œì‹í†µ", "ëˆ„êµ°ê°€ ë§í•˜ê¸°ë¥¼",
                "ì¸í„°ë„·ì—ì„œ ë³¸", "ì¹´í†¡ìœ¼ë¡œ ë°›ì€", "ì „í™”ë¡œ ë“¤ì€"
            ]
            
            credible_count = sum(1 for pattern in credible_patterns if pattern in text)
            non_credible_count = sum(1 for pattern in non_credible_patterns if pattern in text)
            
            # ê¸°ë³¸ ì ìˆ˜ 0.5ì—ì„œ ì‹œì‘
            base_score = 0.5
            credible_bonus = credible_count * 0.1
            non_credible_penalty = non_credible_count * 0.15
            
            final_score = base_score + credible_bonus - non_credible_penalty
            return max(0.0, min(1.0, final_score))
            
        except Exception as e:
            logger.warning(f"ì¶œì²˜ ì‹ ë¢°ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _analyze_claim_strength(self, text: str) -> float:
        """ì£¼ì¥ ê°•ë„ ë¶„ì„"""
        try:
            # ê°•í•œ ì£¼ì¥ í‘œí˜„
            strong_claims = [
                "í™•ì‹¤íˆ", "ë¶„ëª…íˆ", "í‹€ë¦¼ì—†ì´", "100%", "ì ˆëŒ€ì ìœ¼ë¡œ",
                "ì˜ì‹¬ì˜ ì—¬ì§€ ì—†ì´", "ì…ì¦ëœ ì‚¬ì‹¤", "ê³¼í•™ì  ì‚¬ì‹¤"
            ]
            
            # ì•½í•œ ì£¼ì¥ í‘œí˜„
            weak_claims = [
                "ì•„ë§ˆë„", "ì–´ì©Œë©´", "ì¶”ì •", "ê°€ëŠ¥ì„±", "~ì¼ ìˆ˜ë„",
                "~ë¼ê³  ìƒê°", "~ì¼ ê²ƒ ê°™ë‹¤", "~ì¼ì§€ë„"
            ]
            
            strong_count = sum(1 for claim in strong_claims if claim in text)
            weak_count = sum(1 for claim in weak_claims if claim in text)
            
            # ì£¼ì¥ ê°•ë„ ê³„ì‚° (ê°•í• ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            if strong_count > 0 and weak_count == 0:
                return 0.8
            elif strong_count > weak_count:
                return 0.6
            elif weak_count > strong_count:
                return 0.3
            else:
                return 0.5
                
        except Exception as e:
            logger.warning(f"ì£¼ì¥ ê°•ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _check_consistency(self, text: str) -> float:
        """ì¼ê´€ì„± ê²€ì‚¬"""
        try:
            # ë¬¸ì¥ ì„ë² ë”©ì„ ì‚¬ìš©í•œ ì¼ê´€ì„± ê²€ì‚¬
            sentences = text.split('.')
            sentences = [s.strip() for s in sentences if s.strip() and len(s) > 10]
            
            if len(sentences) < 2:
                return 0.7  # ë¬¸ì¥ì´ í•˜ë‚˜ë¿ì´ë©´ ì¤‘ê°„ ì ìˆ˜
            
            # ë¬¸ì¥ ì„ë² ë”© ê³„ì‚°
            embeddings = self.sentence_transformer.encode(sentences)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            from sklearn.metrics.pairwise import cosine_similarity
            import numpy as np
            
            similarity_matrix = cosine_similarity(embeddings)
            
            # ëŒ€ê°ì„  ì œì™¸í•œ ìœ ì‚¬ë„ í‰ê· 
            n = len(similarity_matrix)
            total_similarity = 0
            count = 0
            
            for i in range(n):
                for j in range(i+1, n):
                    total_similarity += similarity_matrix[i][j]
                    count += 1
            
            if count > 0:
                avg_similarity = total_similarity / count
                # ìœ ì‚¬ë„ê°€ ë†’ì„ìˆ˜ë¡ ì¼ê´€ì„±ì´ ë†’ìŒ
                return float(avg_similarity)
            else:
                return 0.5
                
        except Exception as e:
            logger.warning(f"ì¼ê´€ì„± ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _normalize_fact_check_result(self, result) -> float:
        """ì‚¬ì‹¤ í™•ì¸ ê²°ê³¼ë¥¼ 0-1 ì ìˆ˜ë¡œ ì •ê·œí™”"""
        try:
            if isinstance(result, list) and len(result) > 0:
                result = result[0]
            
            if isinstance(result, dict):
                label = result.get('label', '')
                score = result.get('score', 0.0)
                
                # ë¼ë²¨ì— ë”°ë¥¸ ì ìˆ˜ ì¡°ì •
                if 'entailment' in label.lower() or 'true' in label.lower():
                    return score
                elif 'contradiction' in label.lower() or 'false' in label.lower():
                    return 1.0 - score
                else:
                    return score
            
            return 0.5
            
        except Exception as e:
            logger.warning(f"ê²°ê³¼ ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_final_score(self, fact_check: float, source: float, 
                              claim: float, consistency: float) -> float:
        """ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        weights = {
            'fact_check': 0.4,      # ì‚¬ì‹¤ í™•ì¸ì´ ê°€ì¥ ì¤‘ìš”
            'source': 0.3,          # ì¶œì²˜ ì‹ ë¢°ë„
            'claim': 0.2,           # ì£¼ì¥ ê°•ë„
            'consistency': 0.1      # ì¼ê´€ì„±
        }
        
        final_score = (
            fact_check * weights['fact_check'] +
            source * weights['source'] +
            claim * weights['claim'] +
            consistency * weights['consistency']
        )
        
        return round(final_score, 3)
    
    def _determine_credibility_level(self, score: float) -> str:
        """ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •"""
        if score >= 0.8:
            return "very_high"
        elif score >= 0.6:
            return "high"
        elif score >= 0.4:
            return "medium"
        elif score >= 0.2:
            return "low"
        else:
            return "very_low"
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.sentence_transformer:
                del self.sentence_transformer
            if self.fact_check_pipeline:
                del self.fact_check_pipeline
            if self.claim_detection_pipeline:
                del self.claim_detection_pipeline
            
            # BaseAIModelì˜ ì–¸ë¡œë“œ ë©”ì„œë“œ ì‚¬ìš©
            await self.unload_model()
            
            logger.info("âœ… ì‹ ë¢°ë„ ë¶„ì„ ëª¨ë¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì‹ ë¢°ë„ ë¶„ì„ ëª¨ë¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
