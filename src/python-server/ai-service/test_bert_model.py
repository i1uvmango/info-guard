#!/usr/bin/env python3
"""
BERT ê¸°ë°˜ ì‹ ë¢°ì„± ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì €ì¥ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ê³¼ í˜¸í™˜ë˜ëŠ” ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import torch
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from models.bert_credibility_model import BertCredibilityModel
from config.logging_config import get_logger

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)

def test_model_loading():
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("=== BERT ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        model = BertCredibilityModel()
        logger.info("âœ… BERT ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        model_info = model.get_model_info()
        logger.info(f"ëª¨ë¸ ì •ë³´: {model_info}")
        
        # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
        model_path = Path(__file__).parent / "models" / "credibility_model.pth"
        if not model_path.exists():
            logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            return False
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        success = model.load_pretrained_weights(str(model_path))
        if not success:
            logger.error("âŒ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨")
            return False
        
        logger.info("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ")
        
        # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        model.eval()
        logger.info("âœ… ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return False

def test_model_prediction():
    """ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("=== ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # ëª¨ë¸ ë¡œë“œ
        model = BertCredibilityModel()
        model_path = Path(__file__).parent / "models" / "credibility_model.pth"
        model.load_pretrained_weights(str(model_path))
        model.eval()
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        test_texts = [
            "ì´ ì˜ìƒì€ ë§¤ìš° ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
            "ì´ ë‚´ìš©ì€ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ì´ ì •ë³´ëŠ” ê²€ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        ]
        
        for i, text in enumerate(test_texts, 1):
            logger.info(f"í…ŒìŠ¤íŠ¸ {i}: {text}")
            
            # ì˜ˆì¸¡ ì‹¤í–‰
            result = model.predict_multiple_tasks(text)
            
            logger.info(f"  ê²°ê³¼: {result}")
            
            # ê¸°ë³¸ì ì¸ ê²°ê³¼ ê²€ì¦
            assert 'harmlessness' in result, "ë¬´í•´ì„± ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤"
            assert 'honesty' in result, "ì •í™•ì„± ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤"
            assert 'helpfulness' in result, "ë„ì›€ì„± ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ì ìˆ˜ ë²”ìœ„ ê²€ì¦ (0.0 ~ 1.0)
            for key, value in result.items():
                assert 0.0 <= value <= 1.0, f"{key} ì ìˆ˜ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤: {value}"
            
            logger.info(f"  âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_gpu_optimization():
    """GPU ìµœì í™” í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("=== GPU ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        if not torch.cuda.is_available():
            logger.warning("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
            return True
        
        # GPU ì •ë³´ ì¶œë ¥
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"GPU: {gpu_name}")
        logger.info(f"GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
        
        # ëª¨ë¸ ë¡œë“œ
        model = BertCredibilityModel()
        model_path = Path(__file__).parent / "models" / "credibility_model.pth"
        model.load_pretrained_weights(str(model_path))
        model.eval()
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        allocated_memory = torch.cuda.memory_allocated(0) / 1024**3
        cached_memory = torch.cuda.memory_reserved(0) / 1024**3
        
        logger.info(f"í• ë‹¹ëœ GPU ë©”ëª¨ë¦¬: {allocated_memory:.2f}GB")
        logger.info(f"ìºì‹œëœ GPU ë©”ëª¨ë¦¬: {cached_memory:.2f}GB")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì ì ˆí•œì§€ í™•ì¸ (ì „ì²´ ë©”ëª¨ë¦¬ì˜ 80% ì´í•˜)
        if allocated_memory < gpu_memory * 0.8:
            logger.info("âœ… GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì ì ˆí•©ë‹ˆë‹¤")
        else:
            logger.warning("âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ GPU ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_model_performance():
    """ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("=== ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # ëª¨ë¸ ë¡œë“œ
        model = BertCredibilityModel()
        model_path = Path(__file__).parent / "models" / "credibility_model.pth"
        model.load_pretrained_weights(str(model_path))
        model.eval()
        
        # ê¸´ í…ìŠ¤íŠ¸ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        long_text = "ì´ê²ƒì€ ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. " * 100
        logger.info(f"ê¸´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(long_text)} ë¬¸ì")
        
        import time
        start_time = time.time()
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        result = model.predict_multiple_tasks(long_text)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        logger.info(f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
        logger.info(f"ê²°ê³¼: {result}")
        
        # ì²˜ë¦¬ ì‹œê°„ì´ ì ì ˆí•œì§€ í™•ì¸ (5ì´ˆ ì´í•˜)
        if processing_time < 5.0:
            logger.info("âœ… ì²˜ë¦¬ ì‹œê°„ì´ ì ì ˆí•©ë‹ˆë‹¤")
        else:
            logger.warning("âš ï¸ ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ BERT ê¸°ë°˜ ì‹ ë¢°ì„± ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    tests = [
        ("ëª¨ë¸ ë¡œë”©", test_model_loading),
        ("ëª¨ë¸ ì˜ˆì¸¡", test_model_prediction),
        ("GPU ìµœì í™”", test_gpu_optimization),
        ("ëª¨ë¸ ì„±ëŠ¥", test_model_performance)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
                logger.info(f"âœ… {test_name} í…ŒìŠ¤íŠ¸ í†µê³¼")
            else:
                logger.error(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        except Exception as e:
            logger.error(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {e}")
    
    logger.info(f"\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
    logger.info(f"í†µê³¼: {passed}/{total}")
    
    if passed == total:
        logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        return True
    else:
        logger.error("ğŸ’¥ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
