"""
ì½˜í…ì¸  ë¶„ë¥˜ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import time
import logging
import numpy as np
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from models.content_classifier.classifier import ContentClassifier
from models.content_classifier.preprocessor import ContentPreprocessor
from models.content_classifier.trainer import ContentClassifierTrainer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_preprocessor():
    """ì „ì²˜ë¦¬ê¸° í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("ì „ì²˜ë¦¬ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        preprocessor = ContentPreprocessor()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_cases = [
            {
                "title": "ì •ì¹˜ ë‰´ìŠ¤: ëŒ€í†µë ¹, ê²½ì œ ì •ì±… ë°œí‘œ",
                "description": "ì˜¤ëŠ˜ ëŒ€í†µë ¹ì´ ìƒˆë¡œìš´ ê²½ì œ ì •ì±…ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.",
                "tags": ["ì •ì¹˜", "ê²½ì œ", "ëŒ€í†µë ¹", "ì •ì±…"]
            },
            {
                "title": "ì—”í„°í…Œì¸ë¨¼íŠ¸: ìµœì‹  ì˜í™” ë¦¬ë·°",
                "description": "ì´ë²ˆ ì£¼ ê°œë´‰í•œ ì˜í™”ë“¤ì˜ ë¦¬ë·°ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.",
                "tags": ["ì˜í™”", "ë¦¬ë·°", "ì—”í„°í…Œì¸ë¨¼íŠ¸"]
            },
            {
                "title": "ê²½ì œ: ì£¼ì‹ ì‹œì¥ ë™í–¥ ë¶„ì„",
                "description": "ì˜¤ëŠ˜ ì£¼ì‹ ì‹œì¥ì˜ ì£¼ìš” ë™í–¥ì„ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.",
                "tags": ["ì£¼ì‹", "ê²½ì œ", "ì‹œì¥", "ë¶„ì„"]
            }
        ]
        
        for i, case in enumerate(test_cases):
            logger.info(f"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1}: {case['title']}")
            
            result = preprocessor.preprocess_text(
                case['title'], 
                case['description'], 
                case['tags']
            )
            
            logger.info(f"  ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {result['metadata']['title_length']}")
            logger.info(f"  ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸: {result['processed']['combined'][:100]}...")
            
        logger.info("ì „ì²˜ë¦¬ê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"ì „ì²˜ë¦¬ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_classifier():
    """ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # ì‚¬ì „í›ˆë ¨ ëª¨ë¸ ì‚¬ìš©
        classifier = ContentClassifier(use_pretrained=True)
        
        if not classifier.is_loaded:
            logger.error("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            return False
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_contents = [
            {
                "title": "ì •ì¹˜ ë‰´ìŠ¤: êµ­íšŒì—ì„œ ì˜ˆì‚°ì•ˆ í†µê³¼",
                "description": "ì˜¤ëŠ˜ êµ­íšŒì—ì„œ ë‚´ë…„ë„ ì˜ˆì‚°ì•ˆì´ í†µê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "tags": ["ì •ì¹˜", "êµ­íšŒ", "ì˜ˆì‚°", "í†µê³¼"]
            },
            {
                "title": "ê²½ì œ: ë¶€ë™ì‚° ì‹œì¥ ì „ë§",
                "description": "ì „ë¬¸ê°€ë“¤ì´ ë‚´ë…„ ë¶€ë™ì‚° ì‹œì¥ ì „ë§ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
                "tags": ["ê²½ì œ", "ë¶€ë™ì‚°", "ì‹œì¥", "ì „ë§"]
            },
            {
                "title": "ì‹œì‚¬: êµí†µì‚¬ê³  ì¦ê°€ ì¶”ì„¸",
                "description": "ìµœê·¼ êµí†µì‚¬ê³ ê°€ ì¦ê°€í•˜ê³  ìˆì–´ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "tags": ["ì‹œì‚¬", "êµí†µì‚¬ê³ ", "ì•ˆì „", "ì£¼ì˜"]
            },
            {
                "title": "ì—”í„°í…Œì¸ë¨¼íŠ¸: ì•„ì´ëŒ ê·¸ë£¹ ì»´ë°±",
                "description": "ì¸ê¸° ì•„ì´ëŒ ê·¸ë£¹ì´ ìƒˆ ì•¨ë²”ìœ¼ë¡œ ì»´ë°±í•©ë‹ˆë‹¤.",
                "tags": ["ì•„ì´ëŒ", "ì»´ë°±", "ì•¨ë²”", "ì—”í„°í…Œì¸ë¨¼íŠ¸"]
            }
        ]
        
        results = []
        
        for i, content in enumerate(test_contents):
            logger.info(f"ì½˜í…ì¸  {i+1} ë¶„ë¥˜ ì¤‘: {content['title']}")
            
            start_time = time.time()
            
            result = classifier.classify(
                content['title'],
                content['description'],
                content['tags']
            )
            
            processing_time = time.time() - start_time
            
            logger.info(f"  ë¶„ë¥˜ ê²°ê³¼: {result['prediction']['category_name']} (ì‹ ë¢°ë„: {result['prediction']['confidence']:.2f})")
            logger.info(f"  ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
            
            results.append({
                'content': content,
                'result': result,
                'processing_time': processing_time
            })
        
        # ë°°ì¹˜ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
        logger.info("ë°°ì¹˜ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸...")
        batch_results = classifier.batch_classify(test_contents)
        
        for i, result in enumerate(batch_results):
            logger.info(f"  ë°°ì¹˜ ê²°ê³¼ {i+1}: {result['prediction']['category_name']} (ì‹ ë¢°ë„: {result['prediction']['confidence']:.2f})")
        
        logger.info("ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_trainer():
    """í•™ìŠµê¸° í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("í•™ìŠµê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        trainer = ContentClassifierTrainer()
        
        # ëª¨ë¸ ì„¤ì •
        trainer.setup_model()
        
        if not trainer.model or not trainer.tokenizer:
            logger.error("ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì € ì„¤ì • ì‹¤íŒ¨")
            return False
        
        logger.info("ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
        logger.info(f"  ëª¨ë¸: {type(trainer.model).__name__}")
        logger.info(f"  í† í¬ë‚˜ì´ì €: {type(trainer.tokenizer).__name__}")
        
        # ìƒ˜í”Œ ë°ì´í„°ë¡œ ë°ì´í„°ì…‹ ìƒì„± í…ŒìŠ¤íŠ¸ (ê° ì¹´í…Œê³ ë¦¬ë‹¹ 2ê°œì”©)
        sample_data = [
            # ì •ì¹˜ ì¹´í…Œê³ ë¦¬ (0)
            {
                "title": "ì •ì¹˜ ë‰´ìŠ¤ì…ë‹ˆë‹¤.",
                "description": "ì •ì¹˜ ê´€ë ¨ ë‰´ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤.",
                "tags": ["ì •ì¹˜", "ë‰´ìŠ¤"],
                "category": 0
            },
            {
                "title": "ëŒ€í†µë ¹ ì •ì±… ë°œí‘œ",
                "description": "ìƒˆë¡œìš´ ì •ì±…ì´ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "tags": ["ì •ì¹˜", "ëŒ€í†µë ¹", "ì •ì±…"],
                "category": 0
            },
            # ê²½ì œ ì¹´í…Œê³ ë¦¬ (1)
            {
                "title": "ê²½ì œ ë‰´ìŠ¤ì…ë‹ˆë‹¤.",
                "description": "ê²½ì œ ê´€ë ¨ ë‰´ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤.",
                "tags": ["ê²½ì œ", "ë‰´ìŠ¤"],
                "category": 1
            },
            {
                "title": "ì£¼ì‹ ì‹œì¥ ë™í–¥",
                "description": "ì˜¤ëŠ˜ ì£¼ì‹ ì‹œì¥ ìƒí™©ì„ ë¶„ì„í•©ë‹ˆë‹¤.",
                "tags": ["ê²½ì œ", "ì£¼ì‹", "ì‹œì¥"],
                "category": 1
            },
            # ì‹œì‚¬ ì¹´í…Œê³ ë¦¬ (2)
            {
                "title": "ì‹œì‚¬ ë‰´ìŠ¤ì…ë‹ˆë‹¤.",
                "description": "ì‹œì‚¬ ê´€ë ¨ ë‰´ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤.",
                "tags": ["ì‹œì‚¬", "ë‰´ìŠ¤"],
                "category": 2
            },
            {
                "title": "êµí†µì‚¬ê³  ë°œìƒ",
                "description": "ì˜¤ëŠ˜ ë°œìƒí•œ êµí†µì‚¬ê³  ì†Œì‹ì„ ì „í•©ë‹ˆë‹¤.",
                "tags": ["ì‹œì‚¬", "êµí†µì‚¬ê³ ", "ì•ˆì „"],
                "category": 2
            },
            # ì—”í„°í…Œì¸ë¨¼íŠ¸ ì¹´í…Œê³ ë¦¬ (3)
            {
                "title": "ì—”í„°í…Œì¸ë¨¼íŠ¸ ë‰´ìŠ¤ì…ë‹ˆë‹¤.",
                "description": "ì—”í„°í…Œì¸ë¨¼íŠ¸ ê´€ë ¨ ë‰´ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤.",
                "tags": ["ì—”í„°í…Œì¸ë¨¼íŠ¸", "ë‰´ìŠ¤"],
                "category": 3
            },
            {
                "title": "ìƒˆ ì˜í™” ê°œë´‰",
                "description": "ì´ë²ˆ ì£¼ ê°œë´‰í•˜ëŠ” ì˜í™”ë“¤ì„ ì†Œê°œí•©ë‹ˆë‹¤.",
                "tags": ["ì—”í„°í…Œì¸ë¨¼íŠ¸", "ì˜í™”", "ê°œë´‰"],
                "category": 3
            }
        ]
        
        # ê°„ë‹¨í•œ ë°ì´í„°ì…‹ ìƒì„± í…ŒìŠ¤íŠ¸ (ì „ì²˜ë¦¬ë§Œ)
        processed_texts = []
        labels = []
        
        for item in sample_data:
            try:
                preprocessed = trainer.preprocessor.preprocess_text(
                    title=item['title'],
                    description=item.get('description', ''),
                    tags=item.get('tags', [])
                )
                processed_texts.append(preprocessed['processed']['combined'])
                labels.append(item['category'])
            except Exception as e:
                logger.warning(f"ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        logger.info(f"  ì „ì²˜ë¦¬ ì™„ë£Œ: {len(processed_texts)}ê°œ ìƒ˜í”Œ")
        logger.info(f"  ì¹´í…Œê³ ë¦¬ ë¶„í¬: {dict(zip(*np.unique(labels, return_counts=True)))}")
        
        logger.info("í•™ìŠµê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"í•™ìŠµê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_performance():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        classifier = ContentClassifier(use_pretrained=True)
        
        if not classifier.is_loaded:
            logger.error("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            return False
        
        # ëŒ€ëŸ‰ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_contents = []
        categories = ["ì •ì¹˜", "ê²½ì œ", "ì‹œì‚¬", "ê¸°íƒ€"]
        
        for i in range(100):
            category = categories[i % 4]
            test_contents.append({
                "title": f"{category} ê´€ë ¨ ì œëª© {i+1}",
                "description": f"{category}ì— ëŒ€í•œ ì„¤ëª… {i+1}ì…ë‹ˆë‹¤.",
                "tags": [category, f"íƒœê·¸{i+1}"]
            })
        
        # ë°°ì¹˜ ë¶„ë¥˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        results = classifier.batch_classify(test_contents)
        total_time = time.time() - start_time
        
        logger.info(f"  ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/len(test_contents):.3f}ì´ˆ/ê°œ")
        logger.info(f"  ì²˜ë¦¬ ì†ë„: {len(test_contents)/total_time:.1f}ê°œ/ì´ˆ")
        
        # ì •í™•ë„ ê³„ì‚°
        correct = 0
        for i, result in enumerate(results):
            expected_category = i % 4
            if result['prediction']['category_id'] == expected_category:
                correct += 1
        
        accuracy = correct / len(results) * 100
        logger.info(f"  ì •í™•ë„: {accuracy:.1f}%")
        
        logger.info("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("=== ì½˜í…ì¸  ë¶„ë¥˜ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    tests = [
        ("ì „ì²˜ë¦¬ê¸°", test_preprocessor),
        ("ë¶„ë¥˜ê¸°", test_classifier),
        ("í•™ìŠµê¸°", test_trainer),
        ("ì„±ëŠ¥", test_performance)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        logger.info(f"\n--- {test_name} í…ŒìŠ¤íŠ¸ ---")
        try:
            results[test_name] = test_func()
        except Exception as e:
            logger.error(f"{test_name} í…ŒìŠ¤íŠ¸ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {e}")
            results[test_name] = False
    
    # ê²°ê³¼ ìš”ì•½
    logger.info("\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
    for test_name, result in results.items():
        status = "ì„±ê³µ" if result else "ì‹¤íŒ¨"
        logger.info(f"{test_name}: {status}")
    
    success_count = sum(results.values())
    total_count = len(results)
    
    logger.info(f"\nì „ì²´ í…ŒìŠ¤íŠ¸: {success_count}/{total_count} ì„±ê³µ")
    
    if success_count == total_count:
        logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
    else:
        logger.warning("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
