"""
ì½˜í…ì¸  ì „ì²˜ë¦¬ ëª¨ë“ˆ

ìœ íŠœë¸Œ ì˜ìƒì˜ ì œëª©, ì„¤ëª…, íƒœê·¸ë¥¼ ì „ì²˜ë¦¬í•˜ì—¬ ëª¨ë¸ ìž…ë ¥ì— ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""

import re
import json
from typing import Dict, List, Optional
from pathlib import Path


class ContentPreprocessor:
    """ì½˜í…ì¸  ì „ì²˜ë¦¬ í´ëž˜ìŠ¤"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        """
        self.stop_words = self._load_korean_stopwords()
        self.category_mapping = {
            0: "ì •ì¹˜", 1: "ê²½ì œ", 2: "ì‹œì‚¬", 3: "ê¸°íƒ€"
        }
        self.reverse_category_mapping = {v: k for k, v in self.category_mapping.items()}
        
        # í•œêµ­ì–´ íŠ¹ìˆ˜ í‘œí˜„ íŒ¨í„´
        self.korean_patterns = {
            'ì¤„ìž„ë§': r'[ê°€-íž£]+[ã„±-ã…Žã…-ã…£]*',
            'ì´ëª¨í‹°ì½˜': r'[ðŸ˜€-ðŸ™¿ðŸŒ€-ðŸ—¿]',
            'URL': r'https?://[^\s]+',
            'í•´ì‹œíƒœê·¸': r'#[ê°€-íž£a-zA-Z0-9_]+',
            'ë©˜ì…˜': r'@[ê°€-íž£a-zA-Z0-9_]+'
        }
    
    def _load_korean_stopwords(self) -> set:
        """í•œêµ­ì–´ ë¶ˆìš©ì–´ ëª©ë¡ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        # ê¸°ë³¸ í•œêµ­ì–´ ë¶ˆìš©ì–´
        basic_stopwords = {
            'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë•Œ', 'ê³³', 'ë§', 'ì¼',
            'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì €ê²ƒ', 'ê·¸ë•Œ', 'ì´ë•Œ', 'ì €ë•Œ', 'ê·¸ê³³', 'ì´ê³³', 'ì €ê³³',
            'ê·¸ëž˜ì„œ', 'ê·¸ëŸ¬ë©´', 'ê·¸ëŸ°ë°', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ë˜ëŠ”', 'ë˜í•œ',
            'ì•„', 'ì–´', 'ì˜¤', 'ìš°', 'ìœ¼', 'ì´', 'ì•¼', 'ì—¬', 'ìš”', 'ìœ '
        }
        
        # íŒŒì¼ì—ì„œ ì¶”ê°€ ë¶ˆìš©ì–´ ë¡œë“œ ì‹œë„
        try:
            stopwords_file = Path(__file__).parent.parent.parent / "data" / "stopwords.txt"
            if stopwords_file.exists():
                with open(stopwords_file, 'r', encoding='utf-8') as f:
                    file_stopwords = set(line.strip() for line in f if line.strip())
                basic_stopwords.update(file_stopwords)
        except Exception:
            pass  # íŒŒì¼ì´ ì—†ì–´ë„ ê¸°ë³¸ ë¶ˆìš©ì–´ë¡œ ë™ìž‘
        
        return basic_stopwords
    
    def preprocess_text(self, title: str, description: str, tags: List[str]) -> Dict:
        """
        ì œëª©, ì„¤ëª…, íƒœê·¸ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            title: ì˜ìƒ ì œëª©
            description: ì˜ìƒ ì„¤ëª…
            tags: ì˜ìƒ íƒœê·¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
        """
        # ìž…ë ¥ ê²€ì¦
        if not title or not isinstance(title, str):
            raise ValueError("ì œëª©ì€ ë¹„ì–´ìžˆì§€ ì•Šì€ ë¬¸ìžì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        normalized_title = self._normalize_text(title)
        normalized_description = self._normalize_text(description) if description else ""
        normalized_tags = [self._normalize_text(tag) for tag in tags] if tags else []
        
        # ë¶ˆìš©ì–´ ì œê±°
        cleaned_title = self._remove_stopwords(normalized_title)
        cleaned_description = self._remove_stopwords(normalized_description)
        cleaned_tags = [self._remove_stopwords(tag) for tag in normalized_tags]
        
        # ê²°í•©ëœ í…ìŠ¤íŠ¸ ìƒì„±
        combined_text = self._combine_texts(cleaned_title, cleaned_description, cleaned_tags)
        
        return {
            "original": {
                "title": title,
                "description": description,
                "tags": tags
            },
            "processed": {
                "title": cleaned_title,
                "description": cleaned_description,
                "tags": cleaned_tags,
                "combined": combined_text
            },
            "metadata": {
                "title_length": len(title),
                "description_length": len(description) if description else 0,
                "tags_count": len(tags) if tags else 0,
                "processed_length": len(combined_text)
            }
        }
    
    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤."""
        if not text:
            return ""
        
        # ì†Œë¬¸ìž ë³€í™˜ (í•œêµ­ì–´ëŠ” ëŒ€ì†Œë¬¸ìž êµ¬ë¶„ì´ ì—†ì§€ë§Œ ì¼ê´€ì„±ì„ ìœ„í•´)
        text = text.lower()
        
        # URL ì œê±°
        text = re.sub(self.korean_patterns['URL'], '', text)
        
        # í•´ì‹œíƒœê·¸ì—ì„œ # ì œê±°
        text = re.sub(self.korean_patterns['í•´ì‹œíƒœê·¸'], lambda m: m.group()[1:], text)
        
        # ë©˜ì…˜ ì œê±°
        text = re.sub(self.korean_patterns['ë©˜ì…˜'], '', text)
        
        # ì´ëª¨í‹°ì½˜ ì œê±°
        text = re.sub(self.korean_patterns['ì´ëª¨í‹°ì½˜'], '', text)
        
        # íŠ¹ìˆ˜ë¬¸ìž ì •ë¦¬ (í•œê¸€, ì˜ë¬¸, ìˆ«ìž, ê³µë°±ë§Œ ìœ ì§€)
        text = re.sub(r'[^ê°€-íž£a-zA-Z0-9\s]', ' ', text)
        
        # ì—°ì†ëœ ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜
        text = re.sub(r'\s+', ' ', text)
        
        # ì•žë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        return text
    
    def _remove_stopwords(self, text: str) -> str:
        """ë¶ˆìš©ì–´ë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
        if not text:
            return ""
        
        words = text.split()
        filtered_words = [word for word in words if word not in self.stop_words]
        
        return ' '.join(filtered_words)
    
    def _combine_texts(self, title: str, description: str, tags: List[str]) -> str:
        """ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë“¤ì„ ê²°í•©í•©ë‹ˆë‹¤."""
        parts = []
        
        if title:
            parts.append(title)
        
        if description:
            parts.append(description)
        
        if tags:
            parts.extend(tags)
        
        return ' '.join(parts)
    
    def get_category_id(self, category_name: str) -> int:
        """ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ IDë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        return self.reverse_category_mapping.get(category_name, 3)  # ê¸°ë³¸ê°’: ê¸°íƒ€
    
    def get_category_name(self, category_id: int) -> str:
        """ì¹´í…Œê³ ë¦¬ IDë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        return self.category_mapping.get(category_id, "ê¸°íƒ€")
    
    def validate_input(self, title: str, description: str, tags: List[str]) -> bool:
        """ìž…ë ¥ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        if not title or len(title.strip()) == 0:
            return False
        
        if len(title) > 1000:  # ì œëª© ê¸¸ì´ ì œí•œ
            return False
        
        if description and len(description) > 5000:  # ì„¤ëª… ê¸¸ì´ ì œí•œ
            return False
        
        if tags and len(tags) > 50:  # íƒœê·¸ ê°œìˆ˜ ì œí•œ
            return False
        
        return True
