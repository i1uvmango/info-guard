# í•™ìŠµëœ ëª¨ë¸ í†µí•© ê°€ì´ë“œ

## ê°œìš”

Windows í™˜ê²½ì—ì„œ í•™ìŠµëœ `multitask_credibility_model_optimized.pth` ëª¨ë¸ì„ Python AI ì„œë¹„ìŠ¤, Node.js ë°±ì—”ë“œ, Chrome Extensionì— í†µí•©í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.

## í˜„ì¬ ìƒí™© ë¶„ì„

### âœ… ë³´ìœ  ìì‚°
- **í•™ìŠµëœ ëª¨ë¸**: `multitask_credibility_model_optimized.pth` (422MB)
- **ëª¨ë¸ êµ¬ì¡°**: `multitask_credibility_model.py` (10KB, 283ì¤„)
- **ë°ì´í„° ì „ì²˜ë¦¬**: `data_preprocessor.py` (12KB, 319ì¤„)
- **AI ì„œë¹„ìŠ¤**: `main.py` (19KB, 528ì¤„)

### ğŸ” êµ¬ì¡° ë¶„ì„ í•„ìš”
- ëª¨ë¸ ì…ë ¥/ì¶œë ¥ í˜•ì‹ í™•ì¸
- ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê²€ì¦
- API ì—”ë“œí¬ì¸íŠ¸ í˜¸í™˜ì„± í™•ì¸
- Chrome Extension í†µì‹  í˜•ì‹ ê²€ì¦

## í†µí•© ê³„íš

### Phase 1: ëª¨ë¸ êµ¬ì¡° ë¶„ì„ ë° ê²€ì¦

#### 1.1 ëª¨ë¸ íŒŒì¼ ê²€ì¦
```python
# ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
import torch
from models.multitask_credibility_model import MultitaskCredibilityModel

# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
model = MultitaskCredibilityModel()

# í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
model.load_state_dict(torch.load('multitask_credibility_model_optimized.pth'))

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()
```

#### 1.2 ì…ë ¥/ì¶œë ¥ í˜•ì‹ í™•ì¸
```python
# ì˜ˆìƒ ì…ë ¥ í˜•ì‹
sample_input = {
    "text": "ë¶„ì„í•  í…ìŠ¤íŠ¸",
    "title": "ì˜ìƒ ì œëª©",
    "description": "ì˜ìƒ ì„¤ëª…",
    "transcript": "ìë§‰ í…ìŠ¤íŠ¸"
}

# ì˜ˆìƒ ì¶œë ¥ í˜•ì‹
expected_output = {
    "credibility_score": 75.5,
    "bias_score": 0.3,
    "fact_check_score": 0.8,
    "sentiment_score": 0.6,
    "overall_grade": "ë†’ìŒ"
}
```

### Phase 2: Python AI ì„œë¹„ìŠ¤ í†µí•©

#### 2.1 ëª¨ë¸ ë¡œë”© ì„œë¹„ìŠ¤ êµ¬í˜„
```python
# services/model_service.py
class TrainedModelService:
    def __init__(self):
        self.model = None
        self.preprocessor = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.load_model()
    
    def load_model(self):
        """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
        try:
            self.model = MultitaskCredibilityModel()
            self.model.load_state_dict(
                torch.load('multitask_credibility_model_optimized.pth', 
                          map_location=self.device)
            )
            self.model.to(self.device)
            self.model.eval()
            logger.info("í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
```

#### 2.2 ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í†µí•©
```python
# services/preprocessing_service.py
class PreprocessingService:
    def __init__(self):
        self.preprocessor = DataPreprocessor()
    
    def preprocess_video_data(self, video_data):
        """ì˜ìƒ ë°ì´í„° ì „ì²˜ë¦¬"""
        return {
            "text": self._combine_text(video_data),
            "title": video_data.get("title", ""),
            "description": video_data.get("description", ""),
            "transcript": video_data.get("transcript", "")
        }
    
    def _combine_text(self, video_data):
        """í…ìŠ¤íŠ¸ ê²°í•©"""
        texts = [
            video_data.get("title", ""),
            video_data.get("description", ""),
            video_data.get("transcript", "")
        ]
        return " ".join([t for t in texts if t])
```

#### 2.3 ë¶„ì„ ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸
```python
# services/analysis_service.py
class TrainedAnalysisService:
    def __init__(self):
        self.model_service = TrainedModelService()
        self.preprocessing_service = PreprocessingService()
    
    def analyze_video(self, video_data):
        """ì˜ìƒ ì‹ ë¢°ë„ ë¶„ì„"""
        try:
            # ì „ì²˜ë¦¬
            processed_data = self.preprocessing_service.preprocess_video_data(video_data)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            with torch.no_grad():
                predictions = self.model_service.model(processed_data)
            
            # ê²°ê³¼ í›„ì²˜ë¦¬
            result = self._postprocess_predictions(predictions)
            
            return {
                "success": True,
                "data": result,
                "model_version": "trained_v1.0",
                "processing_time": time.time() - start_time
            }
        except Exception as e:
            logger.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
```

### Phase 3: Node.js ë°±ì—”ë“œ í†µí•©

#### 3.1 API ì—”ë“œí¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
```javascript
// routes/analysis.js
router.post('/analyze-video', auth.optionalAuth, async (req, res) => {
    try {
        const { videoId, videoUrl, transcript, metadata } = req.body;
        
        // YouTube ë°ì´í„° ìˆ˜ì§‘
        const videoData = await youtubeService.getVideoInfo(videoId);
        
        // AI ì„œë¹„ìŠ¤ í˜¸ì¶œ (í•™ìŠµëœ ëª¨ë¸)
        const analysisResult = await analysisService.analyzeWithTrainedModel({
            videoId,
            videoUrl,
            transcript: transcript || videoData.transcript,
            metadata: metadata || videoData
        });
        
        // ìºì‹œ ì €ì¥
        await cacheService.set(`analysis:${videoId}`, analysisResult);
        
        res.json(analysisResult);
    } catch (error) {
        logger.error('ë¶„ì„ ì‹¤íŒ¨:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});
```

#### 3.2 ë¶„ì„ ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸
```javascript
// services/analysisService.js
class AnalysisService {
    constructor() {
        this.aiServiceUrl = process.env.AI_SERVICE_URL || 'http://localhost:8000';
        this.aiServiceApiKey = process.env.AI_SERVICE_API_KEY;
    }
    
    async analyzeWithTrainedModel(videoData) {
        try {
            const response = await axios.post(
                `${this.aiServiceUrl}/analyze`,
                {
                    video_id: videoData.videoId,
                    video_url: videoData.videoUrl,
                    transcript: videoData.transcript,
                    metadata: videoData.metadata
                },
                {
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${this.aiServiceApiKey}`
                    },
                    timeout: 30000 // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                }
            );
            
            return this._formatTrainedModelResult(response.data);
        } catch (error) {
            logger.error('AI ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹¤íŒ¨:', error);
            return this._performFallbackAnalysis(videoData);
        }
    }
    
    _formatTrainedModelResult(aiResult) {
        return {
            credibility_score: aiResult.data.credibility_score,
            credibility_grade: this._getGrade(aiResult.data.credibility_score),
            analysis_breakdown: {
                sentiment: aiResult.data.sentiment_score * 100,
                bias: (1 - aiResult.data.bias_score) * 100,
                fact_check: aiResult.data.fact_check_score * 100,
                source: aiResult.data.source_score * 100
            },
            explanation: aiResult.data.explanation,
            confidence: aiResult.data.confidence,
            processing_time: aiResult.processing_time,
            model_version: aiResult.model_version,
            analyzed_at: new Date().toISOString()
        };
    }
}
```

### Phase 4: Chrome Extension í†µí•©

#### 4.1 Content Script ì—…ë°ì´íŠ¸
```javascript
// chrome-extension/content/content.js
class CredibilityUI {
    async analyzeVideo(videoId) {
        try {
            console.log('Info-Guard: í•™ìŠµëœ ëª¨ë¸ë¡œ ë¶„ì„ ì‹œì‘');
            
            const response = await fetch('http://localhost:3000/api/v1/analysis/analyze-video', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    videoId: videoId,
                    videoUrl: window.location.href
                })
            });
            
            const result = await response.json();
            
            if (result.success) {
                this.updateOverlay(result.data);
                console.log('Info-Guard: í•™ìŠµëœ ëª¨ë¸ ë¶„ì„ ì™„ë£Œ', result.data);
            } else {
                console.error('Info-Guard: ë¶„ì„ ì‹¤íŒ¨', result.error);
            }
        } catch (error) {
            console.error('Info-Guard: ë¶„ì„ ì¤‘ ì˜¤ë¥˜', error);
        }
    }
    
    updateOverlay(analysisData) {
        const overlay = this.getOrCreateOverlay();
        
        overlay.innerHTML = `
            <div class="info-guard-overlay">
                <div class="credibility-score">
                    <span class="score">${analysisData.credibility_score}/100</span>
                    <span class="grade">${analysisData.credibility_grade}</span>
                </div>
                <div class="breakdown">
                    <div class="metric">
                        <span class="label">ê°ì •</span>
                        <span class="value">${analysisData.analysis_breakdown.sentiment}%</span>
                    </div>
                    <div class="metric">
                        <span class="label">í¸í–¥</span>
                        <span class="value">${analysisData.analysis_breakdown.bias}%</span>
                    </div>
                    <div class="metric">
                        <span class="label">ì‚¬ì‹¤ê²€ì¦</span>
                        <span class="value">${analysisData.analysis_breakdown.fact_check}%</span>
                    </div>
                </div>
                <div class="explanation">${analysisData.explanation}</div>
            </div>
        `;
    }
}
```

#### 4.2 Popup ì—…ë°ì´íŠ¸
```javascript
// chrome-extension/popup/popup.js
class PopupManager {
    async loadCurrentVideo() {
        try {
            const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });
            
            if (tab.url.includes('youtube.com/watch')) {
                const videoId = this.extractVideoId(tab.url);
                
                // Content Scriptì—ì„œ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                const response = await chrome.tabs.sendMessage(tab.id, {
                    type: 'GET_ANALYSIS_STATUS'
                });
                
                if (response && response.success) {
                    this.displayAnalysisResult(response.data);
                } else {
                    // ì§ì ‘ ë°±ì—”ë“œ API í˜¸ì¶œ
                    await this.performDirectAnalysis(videoId);
                }
            } else {
                this.showNoVideoMessage();
            }
        } catch (error) {
            console.error('Popup ì˜¤ë¥˜:', error);
            this.showErrorMessage();
        }
    }
    
    async performDirectAnalysis(videoId) {
        try {
            const response = await fetch('http://localhost:3000/api/v1/analysis/analyze-video', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ videoId })
            });
            
            const result = await response.json();
            
            if (result.success) {
                this.displayAnalysisResult(result.data);
            } else {
                this.showErrorMessage();
            }
        } catch (error) {
            console.error('ì§ì ‘ ë¶„ì„ ì‹¤íŒ¨:', error);
            this.showErrorMessage();
        }
    }
    
    displayAnalysisResult(data) {
        const scoreElement = document.getElementById('credibility-score');
        const gradeElement = document.getElementById('credibility-grade');
        const breakdownElement = document.getElementById('analysis-breakdown');
        
        scoreElement.textContent = `${data.credibility_score}/100`;
        gradeElement.textContent = data.credibility_grade;
        
        breakdownElement.innerHTML = `
            <div class="breakdown-item">
                <span class="label">ê°ì •</span>
                <span class="value">${data.analysis_breakdown.sentiment}%</span>
            </div>
            <div class="breakdown-item">
                <span class="label">í¸í–¥</span>
                <span class="value">${data.analysis_breakdown.bias}%</span>
            </div>
            <div class="breakdown-item">
                <span class="label">ì‚¬ì‹¤ê²€ì¦</span>
                <span class="value">${data.analysis_breakdown.fact_check}%</span>
            </div>
            <div class="breakdown-item">
                <span class="label">ì¶œì²˜</span>
                <span class="value">${data.analysis_breakdown.source}%</span>
            </div>
        `;
    }
}
```

## êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… Phase 1: ëª¨ë¸ êµ¬ì¡° ë¶„ì„
- [ ] ëª¨ë¸ íŒŒì¼ ë¡œë”© í…ŒìŠ¤íŠ¸
- [ ] ì…ë ¥/ì¶œë ¥ í˜•ì‹ í™•ì¸
- [ ] GPU í˜¸í™˜ì„± ê²€ì¦
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •

### âœ… Phase 2: Python AI ì„œë¹„ìŠ¤ í†µí•©
- [ ] ëª¨ë¸ ë¡œë”© ì„œë¹„ìŠ¤ êµ¬í˜„
- [ ] ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í†µí•©
- [ ] ë¶„ì„ ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…

### âœ… Phase 3: Node.js ë°±ì—”ë“œ í†µí•©
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
- [ ] ë¶„ì„ ì„œë¹„ìŠ¤ ìˆ˜ì •
- [ ] ì‘ë‹µ í˜•ì‹ í†µì¼
- [ ] ìºì‹± ì‹œìŠ¤í…œ ì—°ë™

### âœ… Phase 4: Chrome Extension í†µí•©
- [ ] Content Script ì—…ë°ì´íŠ¸
- [ ] Popup ì¸í„°í˜ì´ìŠ¤ ê°œì„ 
- [ ] ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 

## í…ŒìŠ¤íŠ¸ ê³„íš

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/test_trained_model.py
def test_model_loading():
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    model_service = TrainedModelService()
    assert model_service.model is not None
    assert model_service.model.training == False

def test_preprocessing():
    """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    preprocessor = PreprocessingService()
    video_data = {
        "title": "í…ŒìŠ¤íŠ¸ ì œëª©",
        "description": "í…ŒìŠ¤íŠ¸ ì„¤ëª…",
        "transcript": "í…ŒìŠ¤íŠ¸ ìë§‰"
    }
    processed = preprocessor.preprocess_video_data(video_data)
    assert "text" in processed
    assert len(processed["text"]) > 0

def test_analysis_pipeline():
    """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    analysis_service = TrainedAnalysisService()
    result = analysis_service.analyze_video({
        "title": "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‰´ìŠ¤",
        "description": "ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤",
        "transcript": "ì´ ë‰´ìŠ¤ëŠ” ì‚¬ì‹¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
    })
    assert result["success"] == True
    assert "credibility_score" in result["data"]
```

### í†µí•© í…ŒìŠ¤íŠ¸
```javascript
// tests/integration_test.js
describe('Trained Model Integration', () => {
    test('should analyze video with trained model', async () => {
        const response = await request(app)
            .post('/api/v1/analysis/analyze-video')
            .send({
                videoId: 'test_video_id',
                videoUrl: 'https://youtube.com/watch?v=test'
            });
        
        expect(response.status).toBe(200);
        expect(response.body.success).toBe(true);
        expect(response.body.data.credibility_score).toBeDefined();
        expect(response.body.data.model_version).toBe('trained_v1.0');
    });
});
```

## ì„±ëŠ¥ ìµœì í™”

### GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
torch.cuda.empty_cache()  # ë©”ëª¨ë¦¬ ì •ë¦¬
model.half()  # FP16 ì‚¬ìš©
BATCH_SIZE = 1  # ë°°ì¹˜ í¬ê¸° ì¡°ì •
```

### ì‘ë‹µ ì‹œê°„ ìµœì í™”
```python
# ìºì‹± ì „ëµ
@lru_cache(maxsize=1000)
def analyze_cached(text_hash):
    return model.analyze(text)

# ë¹„ë™ê¸° ì²˜ë¦¬
async def analyze_multiple_videos(video_list):
    tasks = [analyze_video(video) for video in video_list]
    return await asyncio.gather(*tasks)
```

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
```python
# í•´ê²° ë°©ë²•
try:
    model.load_state_dict(torch.load('model.pth', map_location='cpu'))
except Exception as e:
    logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    # Fallback ëª¨ë¸ ì‚¬ìš©
```

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# í•´ê²° ë°©ë²•
torch.cuda.empty_cache()
model = model.cpu()  # CPUë¡œ ì´ë™
# ë˜ëŠ”
model.half()  # FP16 ì‚¬ìš©
```

### API ì‘ë‹µ í˜•ì‹ ë¶ˆì¼ì¹˜
```javascript
// í•´ê²° ë°©ë²•
function normalizeResponse(aiResponse) {
    return {
        credibility_score: aiResponse.credibility_score || 50,
        credibility_grade: getGrade(aiResponse.credibility_score),
        analysis_breakdown: {
            sentiment: aiResponse.sentiment_score * 100,
            bias: (1 - aiResponse.bias_score) * 100,
            fact_check: aiResponse.fact_check_score * 100,
            source: aiResponse.source_score * 100
        }
    };
}
```

## ê²°ë¡ 

í•™ìŠµëœ ëª¨ë¸ì„ í†µí•©í•˜ì—¬ ì‹¤ì œ ì˜ë¯¸ ìˆëŠ” ì‹ ë¢°ë„ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ë‹¨ê³„ë³„ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì§„í–‰í•˜ì—¬ ì•ˆì •ì ì¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê² ìŠµë‹ˆë‹¤.

### ì£¼ìš” ì„±ê³¼ ì˜ˆìƒ
- âœ… ì‹¤ì œ í•™ìŠµëœ ëª¨ë¸ í™œìš©
- âœ… ì •í™•í•œ ì‹ ë¢°ë„ ë¶„ì„
- âœ… ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„
- âœ… ì•ˆì •ì ì¸ ì‹œìŠ¤í…œ ìš´ì˜ 